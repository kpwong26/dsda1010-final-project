---
title: "Final Project Report"
subtitle: "STAT/DSDA 1010; Data Science and Society Using R"
author: "Karissa Wong"
format:
  html:
    toc: true
    number-sections: true
---

# Introduction
## Overview of Data
This research project primarily refers to its corresponding Shiny Dashboard and uses the [Gen AI Misinformation Detection Data (2024-2025)](https://www.kaggle.com/datasets/atharvasoundankar/gen-ai-misinformation-detection-datase-20242025) dataset provided by Atharva Soundankar on Kaggle. The dataset contains realistic simulations of news articles and social media posts (referred to as a “post” in this project) that have spread through 2024-2025 and have all been labeled as potential AI-generated misinformation. Each input of data represents a post and its corresponding attributes, which can be categorized into time, location, author, attributes, credibility, and misinformation.

### Target Variables
For the purpose of this project, the variables that will be focused on are **country, city, token count, readability score, sentiment score, toxicity score, model signature, engagement,** and **if the post is misinformation or not.** A brief explanation of each variables can be found below:

* **Country:** The country that the post was made in.
* **City:** The city, corresponding with its respective country, that the post was made in.
* **Token count:** In AI, a token is a unit of data that comes from breaking down larger words in a text. AI models use tokens to process responses and have limits to how many tokens can be processed at a time. Thus, longer outputs take more time due to the increased number of tokens.
* **Readability score:** A numerical value identifying how easy it is to understand a piece of text, scoring from 0 to 100. A score closer to 100 indicates that the text is very easy to understand.
* **Sentiment score:** A numerical value identifying the overall emotion expressed in a piece of text, scoring from -1 to 1. A score closer to -1 indicates an overall negative tone, closer to 0 indicates a neutral tone, and closer to 1 indicates an overall positive tone.
* **Toxicity score:** A numerical values identifying how harmful or offensive the content of the text is. A score less than 0.5 indicates toxicity and a score greater than 0.5 indicates nontoxicity.
* **Model Signature:** The type of writing style a post most closely reflects. The three model signatures identified were GPT-like (AI), human, and unknown.
* **Engagement:** A numerical value identifying the sum of likes, shares, comments, and views a post has received.
* **Misinformation:** Indicates whether the content in the post is misinformation or authentic information.

## Purpose
Some common attributes distinguish AI writing as its quantity has increased over the years. AI-generated text often have **higher readability scores** than human writing because algorithmic systems favor more **simplistic writing**, resulting in **lower token counts** to produce text faster. AI-generated text also **lacks emotional depth** has because of its structure as a computer, resulting in a **neutral sentiment and toxicity score** (0 and 0.5, respectively).

The goal of this research project is to **study the impact of the increase in Gen AI on misinformation in newswriting and social media posts and to test common attributes of AI writing.** The **primary focus** of this project is to answer the questions of what factors cause text to be marked as GPT-like writing and what is the probability that information marked as GPT-like writing is actually misinformation. Additionally, this project focuses on what countries produce the most AI-generated information and how much engagement each post receives based on their model signature. This analysis can help explore potential patterns in content being marked as AI misinformation, and if there is a need for changing current media writing structure to avoid this problem.

# Analysis
## Detected Misinformation Around the World
In the **"Detected Misinformation Around the World"** tab, the map shows the **unique locations** each post originates from with a filter for model signature, country, and city. The map corresponds with a frequency bar chart, showing the number of misinformation and authentic information posts by model signature, country, city, or all three factors. 

### Findings
Given this sample of data, there was **not a significant difference in the number of AI posts produced by each country.** However, it is worth noting that every post is made from metropolitan areas, corresponding with the trend of larger cities adopting AI because of its ability to provide more funding and research.

## Engagement with Content
In the **“Engagement with Content”** tab, the column chart shows the **relationship between engagement and posts with misinformation versus posts with authentic information.** The chart also has filters for model signature, country, and city to compare engagement with specific model signatures and engagement across countries. 

### Findings
The column chart shows that people overall **engage with more human content** (919,439 cases of engagement) than AI content (849,052 cases of engagement), showing a continuing dominance of human content in social media.

## Misinformation Detection Frequency
In the **“Misinformation Detection Frequency”** tab, the frequency bar chart **compares the count of misinformation content and authentic content by model signature.** In a sample of 157 GPT-like posts and 174 human posts, the amount of **misinformation posts were slightly higher in human posts** (p~1~ = 54%) compared to GPT-like posts (p~2~ = 52.2%).

### Testing for Statistical Significance
A **two-proportion Z-test** was conducted to see if there is a significant difference between p~1~ and p~2~. The **null hypothesis** was there is no difference between the amount of misinformation posts in each model signature and the **alternative hypothesis** was the proportion of misinformation in GPT-like posts is greater than in human posts.
```{r}
# two-proportion z-test
prop.test(x = c(75, 80), n = c(157, 174), alternative = "greater")
```

The conclusions of this test was a **p-value of around 0.4144**, meaning that there is not enough evidence to conclude there is a statistically significant difference given a significance level (α) of 0.05.