---
title: "Generative AI Misinformation Research"
subtitle: "STAT/DSDA 1010; Data Science and Society Using R"
author: Karissa Wong
format:
    revealjs:
        slide-number: true
        preview-links: true
        incremental: true
        theme: serif
---

# Overview

## Gen AI Misinformation Data
This project uses the [Gen AI Misinformation Detection Data (2024-2025)](https://www.kaggle.com/datasets/atharvasoundankar/gen-ai-misinformation-detection-datase-20242025) on Kaggle, which includes:

- Realistic simulations of news articles/social media posts labeled as **potential AI-generated misinformation**
- Time, location, author, attributes, credibility, and misinformation of each post

## Target Variables
For the purpose of this project, we will focus on the following variables:

- Country and city
- Token count
- Readability, sentiment, and toxicity score
- Model signature
- Engagement
- Misinformation

## Purpose
- Study the **impact of Gen AI on misinformation** in newswriting and social media
- Determine **factors** that cause text to be marked as **AI writing**
- Determine if **AI produces more misinformation than humans**
- How much **engagement** each post receives based on model signature

# Analysis

## Detected Misinformation Around the World
Some findings were:

- **Not a significant difference** in the number of GPT-like posts produced by each country
- Every post is produced in **metropolitan areas**, corresponding with current trend of larger cities adopting AI

## Engagement with Content
Some findings were:

- Overall, people engage with **more human content** (919,439 cases of engagement) than AI content (849,052 cases of engagement)
- Shows continuing dominance of human content in social media

## Misinformation Detection Frequency {.smaller}
A **two-proportion Z-test** was conducted to see if there is a significant difference between the **proportion of misinformation** content in GPT-like and human posts.

- 157 GPT-like posts, 174 human posts
- p~1~ = 54% (human), p~2~ = 52.2% (GPT-like)
- **Null Hypothesis:** No difference between the amount of misinformation in each model signature
- **Alternative Hypothesis:** Proportion of misinformation in GPT-like posts is greater than human posts

## Results

```{r}
#| echo: false
#| message: false
library(tidyverse)
gen_ai <- read.csv("generative_ai_misinformation_dataset.csv")
```

```{r}
#| echo: true
#| fig-width: 10
#| fig-height: 4.5
prop.test(x = c(75, 80), n = c(157, 174), alternative = "greater")
```

**Not enough evidence** to conclude there is a statistically significant difference given a significance level (α) of 0.05.

## Attributes of Misinformation Detection
- Each boxplot shows the **summary distribution** of each attribute in posts with **GPT-like** and **human** model signatures
    - **Attributes:** Readability score, toxicity score, sentiment score, token count
- A **two sample T-test** was conducted for each attribute to see if there is a significant difference between the **means** of the GPT-like and human post group

## Readability Score
- **GPT-like group:** Mean = 54.96, Standard deviation = 54.96
- **Human group:** Mean = 55.29, Standard deviation = 14.74
- **Two-sample T-test:**
    - **Null Hypothesis:** No difference between the means of the GPT-like and human group
    - **Alternative Hypothesis:** Difference between the means

## Results {.smaller}

```{r}
#| echo: true
#| fig-width: 10
#| fig-height: 4.5
ai_readability <- gen_ai %>%
  filter(model_signature == "GPT-like") %>%
  pull(readability_score)
  
human_readability <- gen_ai %>%
  filter(model_signature == "human") %>%
  pull(readability_score)
  
t.test(ai_readability, human_readability)
```

**Not enough evidence** to conclude there is a statistically significant difference given a significance level (α) of 0.05.

## Sentiment Score
- **GPT-like group:** Mean = -0.02, Standard deviation = 0.57
- **Human group:** Mean = 0.02, Standard deviation = 0.59
- **Two-sample T-test:**
    - **Null Hypothesis:** No difference between the means of the GPT-like and human group
    - **Alternative Hypothesis:** Difference between the means

## Results {.smaller}

```{r}
#| echo: true
#| fig-width: 10
#| fig-height: 4.5
ai_sentiment <- gen_ai %>%
  filter(model_signature == "GPT-like") %>%
  pull(sentiment_score)
  
human_sentiment <- gen_ai %>%
  filter(model_signature == "human") %>%
  pull(sentiment_score)
  
t.test(ai_sentiment, human_sentiment)
```

**Not enough evidence** to conclude there is a statistically significant difference given a significance level (α) of 0.05.

## Toxicity Score
- **GPT-like group:** Mean = 0.51, Standard deviation = 0.31
- **Human group:** Mean = 0.50, Standard deviation = 0.28
- **Two-sample T-test:**
    - **Null Hypothesis:** No difference between the means of the GPT-like and human group
    - **Alternative Hypothesis:** Difference between the means

## Results {.smaller}

```{r}
#| echo: true
#| fig-width: 10
#| fig-height: 4.5
ai_toxic <- gen_ai %>%
  filter(model_signature == "GPT-like") %>%
  pull(toxicity_score)
  
human_toxic <- gen_ai %>%
  filter(model_signature == "human") %>%
  pull(toxicity_score)
  
t.test(ai_toxic, human_toxic)
```

**Not enough evidence** to conclude there is a statistically significant difference given a significance level (α) of 0.05.

## Token Count
- **GPT-like group:** Mean = 34.22, Standard deviation = 20.43
- **Human group:** Mean = 35.84, Standard deviation = 19.60
- **Two-sample T-test:**
    - **Null Hypothesis:** No difference between the means of the GPT-like and human group
    - **Alternative Hypothesis:** Difference between the means

## Results {.smaller}

```{r}
#| echo: true
#| fig-width: 10
#| fig-height: 4.5
ai_token <- gen_ai %>%
  filter(model_signature == "GPT-like") %>%
  pull(token_count)
  
human_token <- gen_ai %>%
  filter(model_signature == "human") %>%
  pull(token_count)
  
t.test(ai_token, human_token)
```

**Not enough evidence** to conclude there is a statistically significant difference given a significance level (α) of 0.05.

# Conclusion
## Results of the Analysis
- No **significant difference** between amount of misinformation each model produces
- Not enough evidence to show that **average difference** between attributes of AI and human posts is significantly different
- **No definite factor** that causes text to be marked as GPT-like writing

## Takeaways
- **Narrowed gap** between AI and human writing
- Crucial to understand how to identify AI content and misinformation
    - Recognize formulaic structure and repeated phrases
    - Assess credibilty of sources